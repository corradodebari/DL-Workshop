{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-trained Net used on a new set of classes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample based on \"Fine-tune InceptionV3 on a new set of classes\" from https://keras.io/applications/  \n",
    "Upload in a directory images for training, a directory for each class  \n",
    "Upload in a separate directory images for validation, a directory for each class  \n",
    "Upload test images in main directory  \n",
    "\n",
    "First: Install **Keras** on environment  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-requisites library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in /usr/local/lib/python2.7/dist-packages\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python2.7/dist-packages (from keras)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python2.7/dist-packages (from keras)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python2.7/dist-packages (from keras)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python2.7/dist-packages (from keras)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python2.7/dist-packages (from keras)\n",
      "\u001b[33mYou are using pip version 9.0.3, however version 10.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python2.7/dist-packages\n",
      "\u001b[33mYou are using pip version 9.0.3, however version 10.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: Flask in /usr/local/lib/python2.7/dist-packages\n",
      "Requirement already satisfied: Jinja2>=2.10 in /usr/local/lib/python2.7/dist-packages (from Flask)\n",
      "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python2.7/dist-packages (from Flask)\n",
      "Requirement already satisfied: Werkzeug>=0.14 in /usr/local/lib/python2.7/dist-packages (from Flask)\n",
      "Requirement already satisfied: click>=5.1 in /usr/local/lib/python2.7/dist-packages (from Flask)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python2.7/dist-packages (from Jinja2>=2.10->Flask)\n",
      "\u001b[33mYou are using pip version 9.0.3, however version 10.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: Flask-Uploads in /usr/local/lib/python2.7/dist-packages\n",
      "Requirement already satisfied: Flask>=0.8.0 in /usr/local/lib/python2.7/dist-packages (from Flask-Uploads)\n",
      "Requirement already satisfied: Jinja2>=2.10 in /usr/local/lib/python2.7/dist-packages (from Flask>=0.8.0->Flask-Uploads)\n",
      "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python2.7/dist-packages (from Flask>=0.8.0->Flask-Uploads)\n",
      "Requirement already satisfied: Werkzeug>=0.14 in /usr/local/lib/python2.7/dist-packages (from Flask>=0.8.0->Flask-Uploads)\n",
      "Requirement already satisfied: click>=5.1 in /usr/local/lib/python2.7/dist-packages (from Flask>=0.8.0->Flask-Uploads)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python2.7/dist-packages (from Jinja2>=2.10->Flask>=0.8.0->Flask-Uploads)\n",
      "\u001b[33mYou are using pip version 9.0.3, however version 10.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already up-to-date: Flask-Uploads in /usr/local/lib/python2.7/dist-packages\n",
      "Requirement already up-to-date: Flask>=0.8.0 in /usr/local/lib/python2.7/dist-packages (from Flask-Uploads)\n",
      "Requirement already up-to-date: Jinja2>=2.10 in /usr/local/lib/python2.7/dist-packages (from Flask>=0.8.0->Flask-Uploads)\n",
      "Requirement already up-to-date: itsdangerous>=0.24 in /usr/local/lib/python2.7/dist-packages (from Flask>=0.8.0->Flask-Uploads)\n",
      "Requirement already up-to-date: Werkzeug>=0.14 in /usr/local/lib/python2.7/dist-packages (from Flask>=0.8.0->Flask-Uploads)\n",
      "Requirement already up-to-date: click>=5.1 in /usr/local/lib/python2.7/dist-packages (from Flask>=0.8.0->Flask-Uploads)\n",
      "Requirement already up-to-date: MarkupSafe>=0.23 in /usr/local/lib/python2.7/dist-packages (from Jinja2>=2.10->Flask>=0.8.0->Flask-Uploads)\n",
      "\u001b[33mYou are using pip version 9.0.3, however version 10.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install keras\n",
    "! pip install pillow\n",
    "! pip install Flask\n",
    "! pip install Flask-Uploads\n",
    "! pip install Flask-Uploads --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/shared/DL-workshop\r\n"
     ]
    }
   ],
   "source": [
    "! pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check Tensorflow release"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf; print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Input\n",
    "import PIL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup & data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 779 images belonging to 5 classes.\n",
      "\n",
      "Label map in training directory:\n",
      "{'portiera': 1, 'ruote': 2, 'specchi': 3, 'paraurti': 0, 'vetri': 4}\n"
     ]
    }
   ],
   "source": [
    "# dimensions of our images.\n",
    "img_width, img_height = 150, 150\n",
    "\n",
    "train_data_dir =  'data/training' #contains classes to train\n",
    "validation_data_dir = 'data/test' #contains classes for validation\n",
    "\n",
    "nb_train_samples = 779\n",
    "nb_validation_samples = 800\n",
    "nb_epoch = 1\n",
    "nb_classes  = 5\n",
    "model_name = \"inception_retrained_model1\"\n",
    "\n",
    "# Data for Training and Validation\n",
    "# prepare data augmentation configuration\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255)#,\n",
    " #       shear_range=0.2,\n",
    " #       zoom_range=0.2,\n",
    " #       horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=16,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "label_map = (train_generator.class_indices)\n",
    "\n",
    "print (\"\\nLabel map in training directory:\")\n",
    "print label_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training step: go to Load model re-trained cell to skip training phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=16,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "nb_classes =  len(label_map)\n",
    "\n",
    "# create the base pre-trained model\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False)\n",
    "\n",
    "# add a global spatial average pooling layer\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "# let's add a fully-connected layer\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "# and a logistic layer -- let's say we have 200 classes\n",
    "predictions = Dense(nb_classes, activation='softmax')(x)\n",
    "\n",
    "# this is the model we will train\n",
    "model = Model(input=base_model.input, output=predictions)\n",
    "\n",
    "# first: train only the top layers (which were randomly initialized)\n",
    "# i.e. freeze all convolutional InceptionV3 layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "\n",
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "#model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "print \"start history model\"\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    nb_epoch=nb_epoch,\n",
    "    samples_per_epoch=128,\n",
    "    validation_data=validation_generator,\n",
    "    nb_val_samples=nb_validation_samples) \n",
    "\n",
    "# at this point, the top layers are well trained and we can start fine-tuning\n",
    "# convolutional layers from inception V3. We will freeze the bottom N layers\n",
    "# and train the remaining top layers.\n",
    "\n",
    "# let's visualize layer names and layer indices to see how many layers\n",
    "# we should freeze:\n",
    "print(\"base_model\")\n",
    "for i, layer in enumerate(base_model.layers):\n",
    "   print(i, layer.name)\n",
    "\n",
    "\n",
    "# we chose to train the top 2 inception blocks, i.e. we will freeze\n",
    "# the first 172 layers and unfreeze the rest:\n",
    "#for layer in model.layers[:172]:\n",
    "for layer in model.layers[:300]:\n",
    "    layer.trainable = False\n",
    "#for layer in model.layers[172:]:\n",
    "for layer in model.layers[300:]:\n",
    "   layer.trainable = True\n",
    "\n",
    "# we need to recompile the model for these modifications to take effect\n",
    "# we use SGD with a low learning rate\n",
    "from keras.optimizers import SGD\n",
    "model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy')\n",
    "\n",
    "# we train our model again (this time fine-tuning the top 2 inception blocks\n",
    "# alongside the top Dense layers\n",
    "# model.fit_generator(...)\n",
    "# fine-tune the model\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        samples_per_epoch=nb_train_samples,\n",
    "        nb_epoch=nb_epoch,\n",
    "        validation_data=validation_generator,\n",
    "        nb_val_samples=nb_validation_samples,\n",
    "        steps_per_epoch=10)\n",
    "\n",
    "model.save(model_name+\".h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"predictions\")\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversion Net+weights to .pb Tensorflow protobuf format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import keras.backend as K\n",
    "from tensorflow.python.framework import graph_io\n",
    "from tensorflow.python.tools import freeze_graph\n",
    "from tensorflow.core.protobuf import saver_pb2\n",
    "from tensorflow.python.training import saver as saver_lib\n",
    "\n",
    "def convert_keras_to_pb(keras_model, out_names, models_dir, model_filename):\n",
    "    model = load_model(keras_model+\".h5\")\n",
    "    print(model.summary())\n",
    "    K.set_learning_phase(0)\n",
    "    sess = K.get_session()\n",
    "    saver = saver_lib.Saver(write_version=saver_pb2.SaverDef.V2)\n",
    "    checkpoint_path = saver.save(sess, './saved_ckpt', global_step=0, latest_filename='checkpoint_state')\n",
    "    graph_io.write_graph(sess.graph, '.', 'tmp.pb')\n",
    "    freeze_graph.freeze_graph('./tmp.pb', '',\n",
    "                              False, checkpoint_path, out_names,\n",
    "                              \"save/restore_all\", \"save/Const:0\",\n",
    "                              models_dir+model_filename, False, \"\")\n",
    "\n",
    "model_name = \"inception_retrained_model1\"\n",
    "\n",
    "convert_keras_to_pb(model_name,\"dense_4\",\".\",\"trained.pb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model re-trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"inception_retrained_model1\"\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "import numpy\n",
    "\n",
    "# returns a compiled model\n",
    "# identical to the previous one\n",
    "model = load_model(model_name+\".h5\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test on a local image:\n",
      "{ \"name\":\"wheel.jpg\",  \"results\": [ { \"class1\":\"ruote\", \"value\":\"52\" },{ \"class2\":\"vetri\", \"value\":\"12\" },{ \"class3\":\"portiera\", \"value\":\"12\" },{ \"class4\":\"paraurti\", \"value\":\"11\" },{ \"class5\":\"specchi\", \"value\":\"10\" }]  }\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "def inference(imagepath):\n",
    "    img_path = imagepath\n",
    "    img = image.load_img(img_path, target_size=(299, 299))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    \n",
    "    preds = model.predict(x)\n",
    "    \n",
    "    # Decode results\n",
    "    inv_map = {v: k for k, v in label_map.iteritems()}\n",
    "    i=0\n",
    "    a = []\n",
    "    for prob in preds[0]:\n",
    "        a.append([i,int(prob*100)])\n",
    "        i+=1\n",
    "\n",
    "    sorted= numpy.argsort(a,axis=0)\n",
    "    final =[]\n",
    "    for elem in sorted:\n",
    "        final.append([inv_map[elem[1]],int(preds[0][elem[1]]*100)])\n",
    "    inference= numpy.flip(final,axis=0)\n",
    "    \n",
    "    partJson= '{ \\\"name\\\":\\\"'+imagepath+'\\\",  \\\"results\\\": [ '\n",
    "  \n",
    "    for i in range(0,5):\n",
    "        partJson+='{ \\\"class' +str(i+1) + '\\\":\\\"' + str(inference[i][0]) + '\\\", \\\"value\\\":\\\"' + str(inference[i][1]) + '\\\" },' \n",
    "    json = partJson[:-1]+ ']  }'\n",
    "    return json\n",
    "\n",
    "print(\"Test on a local image:\")\n",
    "result = inference('wheel.jpg')\n",
    "print (result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REST Server for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/shared/DL-workshop\n",
      " * Serving Flask app \"/shared/DL-workshop\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: Do not use the development server in a production environment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://0.0.0.0:6006/ (Press CTRL+C to quit)\n",
      "0.0.0.0 - - [22/May/2018 18:24:30] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
      "0.0.0.0 - - [22/May/2018 18:24:46] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/shared/DL-workshop\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from flask import Flask, request, redirect, url_for,Response\n",
    "from werkzeug.utils import secure_filename\n",
    "\n",
    "UPLOAD_FOLDER = os.getcwd()+'/img'\n",
    "ALLOWED_EXTENSIONS = set(['txt', 'pdf', 'png', 'jpg', 'jpeg', 'gif'])\n",
    "\n",
    "#app = Flask(__name__)\n",
    "app = Flask(os.getcwd())\n",
    "\n",
    "app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER\n",
    "\n",
    "def root_dir():  # pragma: no cover\n",
    "    #print('TEST')\n",
    "    #return os.path.abspath(os.path.dirname(__file__))\n",
    "    return os.getcwd()\n",
    "\n",
    "\n",
    "def get_file(filename):  # pragma: no cover\n",
    "    try:\n",
    "\n",
    "        src = os.path.join(root_dir(), filename)\n",
    "        # Figure out how flask returns static files\n",
    "        # Tried:\n",
    "        # - render_template\n",
    "        # - send_file\n",
    "        # This should not be so non-obvious\n",
    "        return open(src).read()\n",
    "    except IOError as exc:\n",
    "        return str(\"NOT_FOUND\")\n",
    "\n",
    "def allowed_file(filename):\n",
    "    return '.' in filename and \\\n",
    "           filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS\n",
    "\n",
    "@app.route('/', methods=['GET', 'POST'])\n",
    "def upload_file():\n",
    "    if request.method == 'POST':\n",
    "        print(root_dir())\n",
    "        # check if the post request has the file part\n",
    "        if 'file' not in request.files:\n",
    "            flash('No file part')\n",
    "            return redirect(request.url)\n",
    "        file = request.files['file']\n",
    "        # if user does not select file, browser also\n",
    "        # submit a empty part without filename\n",
    "        if file.filename == '':\n",
    "            flash('No selected file')\n",
    "            return redirect(request.url)\n",
    "        if file and allowed_file(file.filename):\n",
    "            filename = secure_filename(file.filename)\n",
    "            file.save(os.path.join(app.config['UPLOAD_FOLDER'], filename))\n",
    "            #-----------------------------------------------------------------------------\n",
    "            # INFERENCE\n",
    "            result = inference(os.path.join(app.config['UPLOAD_FOLDER'], filename))\n",
    "            \n",
    "            #-----------------------------------------------------------------------------\n",
    "            \n",
    "            file.save(os.path.join(app.config['UPLOAD_FOLDER'], filename))\n",
    "            open(os.path.join(app.config['UPLOAD_FOLDER'], filename+'.ck'),'w').close()\n",
    "            #return redirect(url_for('upload_file',filename=filename))\n",
    "            return result\n",
    "\n",
    "    return '''\n",
    "    <!doctype html>\n",
    "    <title>Upload new File</title>\n",
    "    <h1>Upload new File</h1>\n",
    "    <form method=post enctype=multipart/form-data>\n",
    "      <p><input type=file name=file>\n",
    "         <input type=submit value=Upload>\n",
    "    </form>\n",
    "    getfile: http://[hostname]:6006/inference?filename=filesent\n",
    "    '''\n",
    "\n",
    "@app.route('/inference', methods=['GET'])\n",
    "def metrics():  # pragma: no cover\n",
    "    fileResponse=request.args.get('filename', '')\n",
    "    content = get_file(UPLOAD_FOLDER+\"/\"+fileResponse+\".json\")\n",
    "    print(UPLOAD_FOLDER+\"/\"+fileResponse+\".json\")\n",
    "    return Response(content, mimetype=\"application/json\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(root_dir())\n",
    "    #app.run(debug=True)\n",
    "    app.run(host='0.0.0.0',port=6006)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
